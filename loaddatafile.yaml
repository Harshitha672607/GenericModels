name: 8Generic Load Dataset
description: Loads data and handles different model types automatically
inputs:
  - name: cdn_url
    type: String
    description: 'CDN URL to download CSV file'
  
  - name: target_column
    type: String
    description: 'Target column name for prediction'
  
  - name: train_split
    type: Float
    description: 'Train split ratio'
  
  - name: shuffle_seed
    type: Integer
    description: 'Random seed for shuffling'
  
  - name: model_type
    type: String
    description: 'Type of model to use'

outputs:
  - name: train_data
    type: Dataset
  - name: test_data
    type: Dataset
  - name: dataset_info
    type: DatasetInfo
  - name: model_config
    type: String

implementation:
  container:
    image: python:3.9
    command:
      - sh
      - -c
      - |
        pip install pandas numpy requests scikit-learn >/dev/null 2>&1
        python -c "
        import os
        import sys
        import io
        import pandas as pd
        import numpy as np
        import requests
        import pickle
        import json
        from urllib.parse import unquote
        from sklearn.model_selection import train_test_split

        cdn_url = sys.argv[1]
        target_column = sys.argv[2]
        train_split = float(sys.argv[3])
        shuffle_seed = int(sys.argv[4])
        model_type = sys.argv[5]
        train_data_path = sys.argv[6]
        test_data_path = sys.argv[7]
        dataset_info_path = sys.argv[8]
        model_config_path = sys.argv[9]

        print('Generic Data Loader')
        print(f'CDN URL: {cdn_url}')
        print(f'Target column: {target_column}')
        print(f'Train split: {train_split}')
        print(f'Shuffle seed: {shuffle_seed}')
        print(f'Model type: {model_type}')

        # Model configurations
        MODEL_CONFIGS = {
            'linear_regression': {
                'model_type': 'linear_regression',
                'normalize': True,
                'description': 'Linear Regression for regression tasks',
                'problem_type': 'regression'
            },
            'logistic_regression': {
                'model_type': 'logistic_regression',
                'normalize': True,
                'max_iter': 1000,
                'random_state': 42,
                'description': 'Logistic Regression for classification tasks',
                'problem_type': 'classification'
            },
            'random_forest': {
                'model_type': 'random_forest',
                'n_estimators': 100,
                'max_depth': 10,
                'random_state': 42,
                'description': 'Random Forest for robust predictions',
                'problem_type': 'auto'
            }
        }

        # Validate model type
        if model_type not in MODEL_CONFIGS:
            print(f'Warning: Unknown model type {model_type}. Using linear_regression.')
            model_type = 'linear_regression'

        # Download and load data
        decoded_url = unquote(cdn_url)
        try:
            print('Downloading CSV')
            response = requests.get(decoded_url, timeout=30)
            response.raise_for_status()
            df = pd.read_csv(io.BytesIO(response.content))
            print(f'Loaded CSV with shape: {df.shape}')
        except Exception as e:
            print(f'Failed to load dataset: {e}')
            raise

        # Data validation
        if target_column not in df.columns:
            print(f'ERROR: Target column {target_column} not found in dataset')
            print(f'Available columns: {list(df.columns)}')
            sys.exit(1)

        # Determine problem type based on model and data
        if model_type == 'logistic_regression':
            problem_type = 'classification'
        elif model_type == 'linear_regression':
            problem_type = 'regression'
        else:  # random_forest - auto-detect
            unique_values = df[target_column].nunique()
            if df[target_column].dtype in ['object', 'category'] or unique_values <= 10:
                problem_type = 'classification'
            else:
                problem_type = 'regression'

        MODEL_CONFIGS[model_type]['problem_type'] = problem_type
        print(f'Problem type: {problem_type}')

        # Handle target encoding for classification
        if problem_type == 'classification' and df[target_column].dtype in ['object', 'category']:
            print('Encoding categorical target for classification')
            df[target_column] = df[target_column].astype('category').cat.codes

        # Shuffle and split data
        df = df.sample(frac=1, random_state=shuffle_seed).reset_index(drop=True)

        train_size = int(len(df) * train_split)
        train_df = df.iloc[:train_size]
        test_df = df.iloc[train_size:]

        print(f'Train shape: {train_df.shape}, Test shape: {test_df.shape}')

        # Feature analysis
        feature_columns = [col for col in df.columns if col != target_column]
        numeric_features = df[feature_columns].select_dtypes(include=[np.number]).columns.tolist()
        categorical_features = df[feature_columns].select_dtypes(include=['object', 'category']).columns.tolist()

        # Prepare dataset info
        dataset_info = {
            'total_samples': len(df),
            'train_samples': len(train_df),
            'test_samples': len(test_df),
            'target_column': target_column,
            'feature_columns': feature_columns,
            'numeric_features': numeric_features,
            'categorical_features': categorical_features,
            'train_split_ratio': train_split,
            'shuffle_seed': shuffle_seed,
            'model_type': model_type,
            'problem_type': problem_type,
            'columns': list(df.columns),
            'dtypes': {col: str(df[col].dtype) for col in df.columns},
        }

        # Get model configuration
        model_config = MODEL_CONFIGS.get(model_type)

        # Ensure directories exist before saving
        os.makedirs(os.path.dirname(train_data_path) or '.', exist_ok=True)
        train_df.to_csv(train_data_path, index=False)

        os.makedirs(os.path.dirname(test_data_path) or '.', exist_ok=True)
        test_df.to_csv(test_data_path, index=False)

        os.makedirs(os.path.dirname(dataset_info_path) or '.', exist_ok=True)
        with open(dataset_info_path, 'wb') as f:
            pickle.dump(dataset_info, f)

        os.makedirs(os.path.dirname(model_config_path) or '.', exist_ok=True)
        with open(model_config_path, 'w') as f:
            json.dump(model_config, f, indent=2)

        print('Dataset processing complete!')
        print(f'Train data saved at: {train_data_path}')
        print(f'Test data saved at: {test_data_path}')
        print(f'Dataset info keys: {list(dataset_info.keys())}')
        print(f'Model config saved at: {model_config_path}')
        " "$0" "$1" "$2" "$3" "$4" "$5" "$6" "$7" "$8"
    args:
      - {inputValue: cdn_url}
      - {inputValue: target_column}
      - {inputValue: train_split}
      - {inputValue: shuffle_seed}
      - {inputValue: model_type}
      - {outputPath: train_data}
      - {outputPath: test_data}
      - {outputPath: dataset_info}
      - {outputPath: model_config}
