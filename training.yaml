name: 3Pgeneric Model Training
description: Generic training component for linear regression, logistic regression, and random forest models with automatic parameter validation

inputs:
  - name: processed_data
    type: Dataset
  - name: preprocessing_pipeline
    type: Model
  - name: preprocessing_config
    type: String
  - name: model_config
    type: String

outputs:
  - name: trained_model
    type: Model
  - name: training_history
    type: String

implementation:
  container:
    image: python:3.9
    command:
      - sh
      - -c
      - |
        pip install pandas numpy scikit-learn joblib >/dev/null 2>&1
        python -c "
        import sys, os, pickle, json, pandas as pd, numpy as np
        from sklearn.linear_model import LogisticRegression, LinearRegression
        from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
        from sklearn.metrics import accuracy_score, mean_squared_error, classification_report

        # Custom JSON encoder to handle NumPy types
        class NumpyEncoder(json.JSONEncoder):
            def default(self, obj):
                if isinstance(obj, (np.integer, np.int64, np.int32, np.int16, np.int8)):
                    return int(obj)
                elif isinstance(obj, (np.floating, np.float64, np.float32, np.float16)):
                    return float(obj)
                elif isinstance(obj, np.ndarray):
                    return obj.tolist()
                elif isinstance(obj, np.bool_):
                    return bool(obj)
                elif pd.isna(obj):
                    return None
                return super().default(obj)

        # Get arguments
        processed_data_path = sys.argv[1]
        preprocessing_pipeline_path = sys.argv[2]
        preprocessing_config_path = sys.argv[3]
        model_config_str = sys.argv[4]
        model_output_path = sys.argv[5]
        history_output_path = sys.argv[6]

        print('Generic Model Training Started')

        # Load inputs
        with open(processed_data_path, 'rb') as f:
            processed_data = pickle.load(f)

        with open(preprocessing_pipeline_path, 'rb') as f:
            preprocessing_pipeline = pickle.load(f)

        with open(preprocessing_config_path, 'r') as f:
            preprocessing_config = json.load(f)

        model_config = json.loads(model_config_str)

        # Extract processed data
        X_train = processed_data['X_train_processed']
        X_test = processed_data['X_test_processed']
        y_train = processed_data['y_train']
        y_test = processed_data['y_test']
        feature_names = processed_data['feature_names']
        problem_type = processed_data['problem_type']

        model_type = model_config.get('model_type', 'logistic_regression')

        print(f'Training Model: {model_type}, Problem Type: {problem_type}')
        print(f'Training data shape: {X_train.shape}')
        print(f'Test data shape: {X_test.shape}')

        # Model selection
        models = {
            'logistic_regression': LogisticRegression(random_state=42, max_iter=1000),
            'linear_regression': LinearRegression(),
            'random_forest_classifier': RandomForestClassifier(random_state=42, n_estimators=100),
            'random_forest_regressor': RandomForestRegressor(random_state=42, n_estimators=100)
        }

        # Select appropriate model
        if problem_type == 'classification':
            if model_type == 'logistic_regression':
                model = models['logistic_regression']
            elif model_type == 'random_forest':
                model = models['random_forest_classifier']
            else:
                model = models['logistic_regression']  
        else:  # regression
            if model_type == 'linear_regression':
                model = models['linear_regression']
            elif model_type == 'random_forest':
                model = models['random_forest_regressor']
            else:
                model = models['linear_regression'] 

        # Train model
        print(f'Training {model_type} for {problem_type} problem...')
        model.fit(X_train, y_train)

        # Make predictions
        y_pred = model.predict(X_test)

        # Calculate metrics - CONVERT ALL NUMPY TYPES TO NATIVE PYTHON TYPES
        training_history = {}
        if problem_type == 'classification':
            accuracy = accuracy_score(y_test, y_pred)
            training_history = {
                'model_type': model_type,
                'problem_type': problem_type,
                'accuracy': float(accuracy),
                'feature_names': [str(f) for f in feature_names],  
                'classes': [str(cls) for cls in model.classes_] if hasattr(model, 'classes_') else [],
                'train_samples': int(len(X_train)),  
                'test_samples': int(len(X_test))     
            }
            print(f'Test Accuracy: {accuracy:.4f}')
        else:
            mse = mean_squared_error(y_test, y_pred)
            training_history = {
                'model_type': model_type,
                'problem_type': problem_type,
                'mse': float(mse),
                'rmse': float(mse ** 0.5),
                'feature_names': [str(f) for f in feature_names],  
                'train_samples': int(len(X_train)),  
                'test_samples': int(len(X_test))     
            }
            print(f'Test MSE: {mse:.4f}')
            print(f'Test RMSE: {mse ** 0.5:.4f}')

        # Save outputs with correct names
        os.makedirs(os.path.dirname(model_output_path) or '.', exist_ok=True)
        with open(model_output_path, 'wb') as f:
            pickle.dump(model, f)

        os.makedirs(os.path.dirname(history_output_path) or '.', exist_ok=True)
        with open(history_output_path, 'w') as f:
            json.dump(training_history, f, indent=2, cls=NumpyEncoder)  

        print('Training completed successfully!')
        print(f'Model saved to: {model_output_path}')
        print(f'Training history saved to: {history_output_path}')
        " "$0" "$1" "$2" "$3" "$4" "$5" "$6"
    args:
      - {inputPath: processed_data}
      - {inputPath: preprocessing_pipeline}
      - {inputPath: preprocessing_config}
      - {inputValue: model_config}
      - {outputPath: trained_model}
      - {outputPath: training_history}
